@ct.lattice
def classical_workflow(train_path, test_path):

    # Load training dataset
    folder_dataset, transformation = file_to_pytorch_transform(train_path)
    dataset = similarity_learning_dataset(folder_dataset, transformation)
    dataloader_train = torch_dataloader(dataset, 8)

    # Load testing dataset
    folder_dataset, transformation = file_to_pytorch_transform(test_path)
    dataset = similarity_learning_dataset(folder_dataset, transformation)
    dataloader_test = torch_dataloader(dataset, 1)

    # Siamese network initialization
    net = init_classical_siamese_network()
    contrastive_loss = classical_contrastive_loss()

    # Train the network
    opt = get_optimizer(net=net, lr=0.0005)
    print('after opt')
    trained_net, loss_history = train_classical_siamese_network(optimizer=opt,
                                                              train_dataloader=dataloader_train,
                                                            network=net,
                                                            loss_function=contrastive_loss,
                                                            epochs=100,
                                                            print_intermediate=True)
    
    # Perform predictions on testing data with the trained network

    results = get_training_results(dataloader_test, trained_net)
    # results = []
    # iterable = iter(dataloader_test)
    # for i in range(5):
    #     x1, x2, label = next(iterable)
    #     scaled_dist, prediction = get_similarity(x1, x2, trained_net)
    #     results.append([label.item(), scaled_dist.item(), prediction.item()])
    return results, loss_history


