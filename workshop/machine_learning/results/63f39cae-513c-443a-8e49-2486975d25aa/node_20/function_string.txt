@ct.electron
def train_classical_siamese_network(train_dataloader, torch_optim, lr, loss_function, epochs, print_intermediate=False):
    
    # Create network instance here
    network = SiameseNetwork()
    optimizer = torch_optim(network.parameters(), lr)
    loss_history = [] 

    # Outer training loop
    for epoch in range(epochs):

        # Iterate over batches
        for i, (img1, img2, label) in enumerate(train_dataloader, 0):

            # Images and labels
            img1, img2, label = img1.cpu(), img2.cpu(), label.cpu()

            # Zero the gradients
            optimizer.zero_grad()

            # Pass in the two images into the network and obtain two outputs
            output1, output2 = network.cpu()(img1, img2)

            # Pass the outputs of the networks and label into the loss function
            loss_contrastive = loss_function(output1, output2, label)

            # Calculate the backpropagation
            loss_contrastive.backward()

            # Optimize
            optimizer.step()

            # Loss appended at the end of each batch
            loss_history.append(loss_contrastive.item())

            # Every 10 epochs print out the loss
        if print_intermediate:
            print(f"Epoch number {epoch}\n Current loss {loss_contrastive.item()}\n")
    return network, loss_history


