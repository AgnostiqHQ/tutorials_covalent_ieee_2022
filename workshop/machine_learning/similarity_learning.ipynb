{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity learning with Covalent\n",
    "\n",
    "In this workshop, you will learn how to use Covalent to manage hybrid quantum-classical workflows for the task of similarity learning. Specfically, within the same workflow, we will dispatch a hybrid quantum-classical machine learning (ML) algorithm and a purely classical ML algorithm to recognize *similar* 2x2 pixel images.\n",
    "\n",
    "While this is a toy problem, it outlines a crucial workflow used to compare the quality of classical and quantum ML models.\n",
    "\n",
    "First, let's import the modules we need for this workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Loading and preparing the training and testing datasets](#load_data)\n",
    "2. [A quick visual introduction to the datasets](#vis_intro)\n",
    "3. [Classical Siamese networks](#classical_siamese)\n",
    "4. [Quantum similarity networks](#quantum_similarity)\n",
    "\n",
    "\n",
    "<!-- 2. [Some paragraph](#paragraph1)\n",
    "    1. [Sub paragraph](#subparagraph1)\n",
    "3. [Another paragraph](#paragraph2) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from itertools import cycle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "import covalent as ct\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the training and testing datasets <a name=\"load_data\"></a>\n",
    "\n",
    "To begin, it will be useful to locally resolve the path to the relevant datasets shipping with this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "pixel_train = \"\".join([base_path, \"/data/pixel_grid/training\"])\n",
    "pixel_test = \"\".join([base_path, \"/data/pixel_grid/testing\"])\n",
    "faces_example = \"\".join([base_path, \"/data/faces/training\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need a simple electron to read a dataset from file into the format required for `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def file_to_pytorch_transform(file_root_dir, transform_dims=(2, 2)):\n",
    "    # Load the training dataset\n",
    "    folder_dataset = datasets.ImageFolder(root=file_root_dir)\n",
    "\n",
    "    # Resize the images and transform to tensors\n",
    "    transformation = transforms.Compose([transforms.Resize(transform_dims),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "    return folder_dataset, transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with `PyTorch` compatible data, we need to perform some pre-processing to make it suitable for the similarity learning task. That is, we need to produce data tuples $(x, \\tilde{x}, y_{x, \\tilde{x}})$. To do so, we define the utility class `SimilarityModelDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityModelDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "        #We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #Look untill the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "\n",
    "            while True:\n",
    "                #Look untill a different class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within an electron, we call an instance of the `SimilarityModelDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def similarity_learning_dataset(folder_dataset, transformation):\n",
    "    dataset = SimilarityModelDataset(folder_dataset, transformation)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in a final data-processing step, we create an electron to create a `torch` `DataLoader` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def torch_dataloader(dataset, batch_size, shuffle=True):\n",
    "    dataloader = DataLoader(dataset, shuffle=shuffle, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick visual introduction to the datasets <a name=\"vis_intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the purpose of an electron is to be executed within a `ct.lattice` (i.e as part of a workflow), they can also be executed locally. Let's try a local execution to demonstrate the contents of our training dataset with the context of a more realistic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pixels dataset\n",
    "folder_dataset, transformation = file_to_pytorch_transform(pixel_train)\n",
    "dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "dataloader_pixels = torch_dataloader(dataset, 1)\n",
    "\n",
    "# Display a couple of items from the training dataset\n",
    "fig, axs = plt.subplots(5, 2, sharex=True, sharey=True, figsize=[4, 10])\n",
    "\n",
    "iterarable_pixels = iter(dataloader_pixels)\n",
    "for i in range(5):\n",
    "    # Pixels first\n",
    "    x1_pixel, x2_pixel, label_pixel = next(iterarable_pixels)\n",
    "    axs[i, 0].imshow(x1_pixel[0, 0, :, :], cmap=\"Greys\")\n",
    "    axs[i, 1].imshow(x2_pixel[0, 0, :, :], cmap=\"Greys\")\n",
    "    axs[i, 0].set_xticks([]); axs[i, 1].set_xticks([])\n",
    "    axs[i, 0].set_yticks([]); axs[i, 1].set_yticks([])\n",
    "    # Display label\n",
    "    if label_pixel == 1:\n",
    "        axs[i, 0].set_ylabel('Dissimilar', color=\"red\")\n",
    "    else:\n",
    "        axs[i, 0].set_ylabel('Similar', color=\"green\")\n",
    "print(label_pixel.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that images labelled as **similar** ($y_{x \\tilde{x}} = 0$) are those sharing a left or right side with zeroed-out pixels. Those which are **dissimilar** ($y_{x \\tilde{x}} = 1$)have zeroed-out pixels on opposite sides.\n",
    "\n",
    "Now in the context of a more realistic dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load faces dataset\n",
    "folder_dataset, transformation = file_to_pytorch_transform(faces_example, transform_dims=(100, 100))\n",
    "dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "dataloader_faces = torch_dataloader(dataset, 1)\n",
    "iterable_faces = iter(dataloader_faces)\n",
    "\n",
    "fig, axs = plt.subplots(5, 2, sharex=True, sharey=True, figsize=[4, 10])\n",
    "for i in range(5):\n",
    "    # Faces second\n",
    "    x1_face, x2_face, label_face = next(iterable_faces)\n",
    "    axs[i, 0].imshow(x1_face[0, 0, :, :], cmap=\"Greys_r\")\n",
    "    axs[i, 1].imshow(x2_face[0, 0, :, :], cmap=\"Greys_r\")\n",
    "    axs[i, 0].set_xticks([]); axs[i, 1].set_xticks([])\n",
    "    axs[i, 0].set_yticks([]); axs[i, 1].set_yticks([])\n",
    "\n",
    "    # Display label\n",
    "    if label_face == 1:\n",
    "        axs[i, 0].set_ylabel('Dissimilar', color=\"red\")\n",
    "    else:\n",
    "        axs[i, 0].set_ylabel('Similar', color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, things are a little more obvious. If the image is of the same person, they are **similar** ($y_{x \\tilde{x}} = 0$). If they display a different person, they are **dissimilar** ($y_{x \\tilde{x}} = 1$). It is now clear that an algorithm capable of performing such distinctions is useful in areas like facial recognition.\n",
    "\n",
    "Anyways, let's proceed with our 2x2 pixel example and devise a classical and quantum algorithm capable of learning these notions of similarity. Let's start classical!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Siamese networks <a name=\"classical_siamese\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classical Siamese network tackles the similarity learning task by jointly training twin (think Siamese...) neural networks using a **contrastive loss**. A typical layout of a Siamese network is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A schematic of a classical Siamese network.](./images/siamese_network.png)\n",
    "\n",
    "Source: <https://www.youtube.com/watch?v=4S-XDefSjTM>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While such networks usually involve dimension reduction of the image (via something like `torch.nn.MaxPool2d`) to create a low-dimensional latent space, we are already working with 2x2 pixel grayscale images so we skip this part. \n",
    "\n",
    "Lets create a `PyTorch` network involing convolutional and linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=2, stride=1, padding='same', padding_mode=\"zeros\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Maxpooling here if image was larger dimensions...\n",
    "            \n",
    "            nn.Conv2d(2, 4, kernel_size=2, stride=1, padding='same', padding_mode=\"zeros\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Maxpooling here if image was larger dimensions...\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=2, stride=1, padding='same', padding_mode=\"zeros\"),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Setting up the Sequential of Fully Connected linear Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the raw (pre sigmoidal) similiarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a network which outputs a latent vector upon insertion of an image. Now, in a Siamese network, we require comparison of the latent vector upon insertion of two different images $x$ and $\\tilde{x}$. This defines the contrastive loss. Let's make a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ClassicalContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Calculate the euclidean distance and calculate the contrastive loss\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "    \n",
    "\n",
    "        loss_contrastive = 2*(torch.sigmoid(loss_contrastive) - 0.5) # Mean square loss is positive. Rescale in 0 1\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a corresponding electron to create a `ClassicalContrastiveLoss` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def classical_contrastive_loss(margin=2):\n",
    "    contrastive_loss = ClassicalContrastiveLoss(margin)\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're nearly there! We need an electron to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def train_classical_siamese_network(train_dataloader, torch_optim, lr, loss_function, epochs, print_intermediate=False):\n",
    "    \n",
    "    # Create network instance here\n",
    "    network = SiameseNetwork()\n",
    "    optimizer = torch_optim(network.parameters(), lr)\n",
    "    loss_history = [] \n",
    "\n",
    "    # Outer training loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Iterate over batches\n",
    "        for i, (img1, img2, label) in enumerate(train_dataloader, 0):\n",
    "\n",
    "            # Images and labels\n",
    "            img1, img2, label = img1.cpu(), img2.cpu(), label.cpu()\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Pass in the two images into the network and obtain two outputs\n",
    "            output1, output2 = network.cpu()(img1, img2)\n",
    "\n",
    "            # Pass the outputs of the networks and label into the loss function\n",
    "            loss_contrastive = loss_function(output1, output2, label)\n",
    "\n",
    "            # Calculate the backpropagation\n",
    "            loss_contrastive.backward()\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # Loss appended at the end of each batch\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "            # Every 10 epochs print out the loss\n",
    "        if print_intermediate:\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "    return network, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and and electron to get the simlarity between unseen images and return a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_similarity(x1, x2, trained_net):\n",
    "    output1, output2 = trained_net(x1.cpu(), x2.cpu())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    scaled_dist = 2*(torch.sigmoid(euclidean_distance) - 0.5)\n",
    "    prediction = torch.round(scaled_dist)\n",
    "    return scaled_dist, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_testing_results(dataloader_test, trained_net, num_dat=None):\n",
    "    results = []\n",
    "    iterable = iter(dataloader_test)\n",
    "    if num_dat is None:\n",
    "        num_dat = len(dataloader_test.dataset)\n",
    "    for i in range(num_dat):\n",
    "        x1, x2, label = next(iterable)\n",
    "        scaled_dist, prediction = get_similarity(x1, x2, trained_net)\n",
    "        results.append([label.item(), prediction.item(), scaled_dist.item()])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to construct a simple exemplar workflow. We shall load the training and testing data, perform preprocessing, train the network and see how predictions line up with the ground truth for 5 elements of the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def classical_workflow(train_path, test_path, train_batch, pytorch_optimizer, epochs, lr, print_intermediate, test_num_dat):\n",
    "\n",
    "    # Load training dataset\n",
    "    folder_dataset, transformation = file_to_pytorch_transform(train_path)\n",
    "    dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "    dataloader_train = torch_dataloader(dataset, train_batch)\n",
    "\n",
    "    # Load testing dataset\n",
    "    folder_dataset, transformation = file_to_pytorch_transform(test_path)\n",
    "    dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "    dataloader_test = torch_dataloader(dataset, 1, False)\n",
    "\n",
    "    # Siamese network initialization\n",
    "    contrastive_loss = classical_contrastive_loss()\n",
    "\n",
    "    # Train the network\n",
    "    trained_net, loss_history = train_classical_siamese_network(torch_optim=pytorch_optimizer,#torch.optim.Adam,\n",
    "                                                               train_dataloader=dataloader_train,\n",
    "                                                               loss_function=contrastive_loss,\n",
    "                                                               epochs=epochs,\n",
    "                                                               print_intermediate=print_intermediate, lr=lr)\n",
    "    \n",
    "    # Perform predictions on testing data with the trained network\n",
    "    results = get_testing_results(dataloader_test, trained_net, num_dat=test_num_dat)\n",
    "    \n",
    "    return results, loss_history, trained_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first time, let's launch the covalent server. Launch from your terminal and purge:\n",
    "covalent start --ignore-migrations\n",
    "`covalent purge --hell yeah`, `covalent start`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_id = ct.dispatch(classical_workflow)(train_path=pixel_train,\n",
    "                                              test_path=pixel_test,\n",
    "                                              train_batch=8,\n",
    "                                              pytorch_optimizer=torch.optim.Adam,\n",
    "                                              epochs=5,\n",
    "                                              lr=0.005,\n",
    "                                              print_intermediate=False)\n",
    "ct_results = ct.get_result(dispatch_id=dispatch_id, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the success of the workflow. Navigate to <http://localhost:48008/> to view the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, loss_history, trained_net = ct_results.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch iterations')\n",
    "plt.ylabel('Classical loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum similarity networks <a name=\"quantum_similarity\"></a>\n",
    "\n",
    "Same workflow as Siamese network, but using a quantum cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('lightning.qubit', wires=5)\n",
    "\n",
    "@ct.electron\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def similarity_circuit(x1, x2, alpha1, alpha2, wires, ansatz=qml.QAOAEmbedding, measure_bits=2):\n",
    "    # Basically a kernel\n",
    "    ansatz(features=x1, weights=alpha1, wires=wires)\n",
    "    qml.adjoint(ansatz)(features=x2, weights=alpha2, wires=wires)\n",
    "    # Measure only first measure_bits qubits.\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(measure_bits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def quantum_cost(batch, alpha1, alpha2, wires, similarity_circuit, measure_bits=2):\n",
    "    x1_batch, x2_batch, label_batch = batch\n",
    "    batch_size = len(x1_batch)\n",
    "    all_costs = torch.zeros(batch_size)\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        x1 = torch.flatten(x1_batch[i]) # embedding requires flat tensor\n",
    "        x2 = torch.flatten(x2_batch[i])\n",
    "        label = label_batch[i]\n",
    "\n",
    "        expecs = similarity_circuit(x1, x2, alpha1, alpha2, wires, ansatz=qml.QAOAEmbedding, measure_bits=measure_bits)\n",
    "        dist = (torch.mean(expecs) + 1)/2 # Now in 0 - 1\n",
    "        loss_contrastive = (1-label) * torch.pow(dist, 2) +\\\n",
    "                       (label) * torch.pow(torch.clamp(0.9 - dist, min=0.0), 2)\n",
    "        all_costs[i] = loss_contrastive\n",
    "    avg_loss = torch.mean(all_costs)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_random_init_params(n_qubits, layers, ansatz=qml.QAOAEmbedding):\n",
    "    alpha1 = torch.tensor(np.random.uniform(size=ansatz.shape(layers, n_qubits)), requires_grad=True)\n",
    "    alpha2 = torch.tensor(np.random.uniform(size=ansatz.shape(layers, n_qubits)), requires_grad=True)\n",
    "    return alpha1, alpha2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def train_quantum_net(lr, init_params, dataloader_train, batch_cost_func, similarity_circuit,\n",
    "                      measure_bits, epochs, pytorch_optimizer, print_intermediate=False):\n",
    "\n",
    "    opt = pytorch_optimizer(init_params, lr=lr)\n",
    "    dataiter = iter(dataloader_train)\n",
    "    alpha1, alpha2 = init_params\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        loss = batch_cost_func(next(dataiter), alpha1, alpha2, \n",
    "                               similarity_circuit=similarity_circuit,\n",
    "                               wires=dev.wires, measure_bits=measure_bits)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    loss_history = [] \n",
    "    for epoch in range(epochs):\n",
    "        dataiter = iter(dataloader_train)\n",
    "        for i in range(len(dataloader_train)):\n",
    "            loss = opt.step(closure)\n",
    "            loss_history.append(loss.item()) \n",
    "        if epoch % 10 == 0 and print_intermediate:\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss.item()}\\n\")\n",
    "    return loss_history, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_quantum_prob(x1, x2, label, alpha1, alpha2, wires, similarity_circuit, ansatz=qml.QAOAEmbedding, measure_bits=2):\n",
    "    x1 = torch.flatten(x1) # embedding requires flat tensor\n",
    "    x2 = torch.flatten(x2)\n",
    "    expecs = similarity_circuit(x1, x2, alpha1, alpha2, wires, ansatz=ansatz, measure_bits=measure_bits)\n",
    "    dist = (torch.mean(expecs) + 1)/2 # Now in 0 - 1\n",
    "    return dist\n",
    "\n",
    "@ct.electron\n",
    "def quantum_predict(quantum_prob):\n",
    "    return torch.round(quantum_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_test_results_quantum(dataloader_test, opt_params, prob_func, predict_func, wires, measure_bits, num_dat=None):\n",
    "    # pass a dataloader with 1 batch size to cycle through testing\n",
    "    alpha1, alpha2 = opt_params\n",
    "    iterable = iter(dataloader_test)\n",
    "    results = []\n",
    "    if num_dat is None:\n",
    "        num_dat = len(dataloader_test.dataset)\n",
    "    for i in range(num_dat):\n",
    "        x1, x2, label = next(iterable)\n",
    "        x1 = torch.flatten(x1) # embedding requires flat tensor\n",
    "        x2 = torch.flatten(x2)\n",
    "\n",
    "        prob = prob_func(x1, x2, label, alpha1, alpha2, wires, similarity_circuit, ansatz=qml.QAOAEmbedding, measure_bits=2)\n",
    "        prediction = predict_func(prob)\n",
    "        results.append([label.item(), prediction.item(), prob.item()])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def quantum_workflow(train_path, test_path, train_batch, pytorch_optimizer, epochs, lr, print_intermediate, test_num_dat):\n",
    "\n",
    "    # Get training and testing dataloaders\n",
    "    folder_dataset, transformation = file_to_pytorch_transform(train_path)\n",
    "    dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "    dataloader_train = torch_dataloader(dataset, train_batch)\n",
    "\n",
    "    folder_dataset, transformation = file_to_pytorch_transform(test_path)\n",
    "    dataset = similarity_learning_dataset(folder_dataset, transformation)\n",
    "    dataloader_test = torch_dataloader(dataset, 1, False)\n",
    "\n",
    "    # Get intial parameters for quantum net. We hardcode the 5 qubit 2 layer QAOA ansatz.\n",
    "    alpha1, alpha2 = get_random_init_params(5, 2)\n",
    "\n",
    "    # pass relevant electron functions to training routine. Measure_bits=2 is also hardcoded\n",
    "    loss_history, opt = train_quantum_net(lr=lr, init_params=[alpha1, alpha2],\n",
    "                                          dataloader_train=dataloader_train,\n",
    "                                          batch_cost_func=quantum_cost, # is an electron function\n",
    "                                          similarity_circuit=similarity_circuit, # is an electron function\n",
    "                                          measure_bits=2, epochs=epochs,\n",
    "                                          pytorch_optimizer=pytorch_optimizer,\n",
    "                                          print_intermediate=False)\n",
    "    results = get_test_results_quantum(dataloader_test, opt.param_groups[0]['params'],\n",
    "                                       prob_func=get_quantum_prob, \n",
    "                                       predict_func=quantum_predict,\n",
    "                                       wires=dev.wires,\n",
    "                                       measure_bits=2, num_dat=test_num_dat)\n",
    "    return results, loss_history, opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_id = ct.dispatch(quantum_workflow)(train_path=pixel_train,\n",
    "                                            test_path=pixel_test,\n",
    "                                            train_batch=8,\n",
    "                                            pytorch_optimizer=torch.optim.Adam,\n",
    "                                            epochs=5,\n",
    "                                            lr=0.05,\n",
    "                                            print_intermediate=False,\n",
    "                                            test_num_dat=5)\n",
    "wf_results = ct.get_result(dispatch_id=dispatch_id, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, loss_history, trained_opt = wf_results.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Batch iterations\")\n",
    "plt.ylabel(\"Quantum loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A heterogeneous workflow: comparing accuracy scores\n",
    "\n",
    "Compare the accuracy scores upon testing for the quantum and classical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_accuracy_score(results_tuples):\n",
    "    # Process the (label, prob, prediciton) tuple and return an accuracy percentage\n",
    "    correct_counter = 0\n",
    "    for result in results:\n",
    "        if result[0] == result[1]: # Label matches prediction\n",
    "            correct_counter += 1\n",
    "        else:\n",
    "            continue\n",
    "    return 100*correct_counter/len(results_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def quantum_classical_workflow(train_path, test_path, train_batch, pytorch_optimizer, epochs, lr_c, lr_q, print_intermediate):\n",
    "\n",
    "    # Run the classical sublattice\n",
    "    results_classical, loss_history_classical, trained_net_c = \\\n",
    "         classical_workflow(train_path=pixel_train,\n",
    "                            test_path=pixel_test,\n",
    "                            train_batch=train_batch,\n",
    "                            pytorch_optimizer=pytorch_optimizer,\n",
    "                            epochs=epochs,\n",
    "                            lr=lr_c,\n",
    "                            print_intermediate=print_intermediate)\n",
    "\n",
    "    # Run the quantum sublattice\n",
    "    results_quantum, loss_history_quantum, trained_opt_q = \\\n",
    "         quantum_workflow(train_path=train_path,\n",
    "                          test_path=test_path,\n",
    "                          train_batch=train_batch,\n",
    "                          pytorch_optimizer=pytorch_optimizer,\n",
    "                          epochs=epochs,\n",
    "                          lr=lr_q,\n",
    "                          print_intermediate=print_intermediate)\n",
    "\n",
    "    # Calculate the accuracy scores\n",
    "    acc_classical = get_accuracy_score(results_classical)\n",
    "    acc_quantum = get_accuracy_score(results_quantum)\n",
    "    return acc_classical, acc_quantum, trained_net_c, trained_opt_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_id = ct.dispatch(quantum_classical_workflow)(train_path=pixel_train,\n",
    "                                                      test_path=pixel_test,\n",
    "                                                      train_batch=8,\n",
    "                                                      pytorch_optimizer=torch.optim.Adam,\n",
    "                                                      epochs=25,\n",
    "                                                      lr_q=0.05,\n",
    "                                                      lr_c=0.0005,\n",
    "                                                      print_intermediate=False)\n",
    "wf_results = ct.get_result(dispatch_id=dispatch_id, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_classical, acc_quantum, trained_net_c, trained_opt_q = wf_results.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score for classical Siamese network:\", acc_classical, \"%\")\n",
    "print(\"Accuracy score for quantum similarity network:\", acc_quantum, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating learnt notions of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def generate_left_right_transition(num_images):\n",
    "    image_pairs = []\n",
    "    left_image = torch.tensor([[[1.0, 0],\n",
    "                               [1.0, 0]]], requires_grad=False, dtype=torch.float32)\n",
    "    for intensity in torch.tensor(np.linspace(0, 1, num_images), requires_grad=False, dtype=torch.float32):\n",
    "        image = torch.tensor([[[1.0-intensity, intensity],\n",
    "                              [1.0-intensity, intensity]]], requires_grad=False, dtype=torch.float32)\n",
    "        image_pairs.append([left_image, image, 0]) # 2 is the label; different on purpose to previous\n",
    "    return image_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pairs = generate_left_right_transition(20)\n",
    "fig, axs = plt.subplots(1, 20, figsize=[15, 2])\n",
    "for i, image_pair in enumerate(image_pairs):\n",
    "    axs[i].imshow(image_pair[1][0], vmin=0, vmax=1, cmap=\"Greys\")\n",
    "    axs[i].set_yticks([]); axs[i].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def similarity_experiment(num_images, trained_net_c, trained_opt_q):\n",
    "    image_pairs = generate_left_right_transition(num_images)\n",
    "    dataloader_test = torch_dataloader(image_pairs, shuffle=False, batch_size=1)\n",
    "    results_c = get_testing_results(dataloader_test, trained_net)\n",
    "    results_q = get_test_results_quantum(dataloader_test, trained_opt_q.param_groups[0]['params'],\n",
    "                                         prob_func=get_quantum_prob, \n",
    "                                         predict_func=quantum_predict,\n",
    "                                         wires=dev.wires,\n",
    "                                         measure_bits=2)\n",
    "    return results_c, results_q\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_id = ct.dispatch(similarity_experiment)(num_image=20, trained_net_c=trained_net_c, trained_opt_q=trained_opt_q)\n",
    "ct_results = ct.get_result(dispatch_id=dispatch_id, wait=True)\n",
    "results_c, results_q = ct_results.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([results_c[i][2] for i in range(len(results_c))], label=\"Clasical Siamese network\")\n",
    "plt.plot([results_q[i][2] for i in range(len(results_q))], label=\"Quantum similarity network\")\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('algo-time-series')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebe333cbe530cfdcf63924802829da59b1d6692df1c9241ebe53f375aea617cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
